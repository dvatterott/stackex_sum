{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries and get stockoverflow library set up to make api requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import stackexchange\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "api_key = '5*wCDZgONnIJ*aiaYeKjQQ(('\n",
    "\n",
    "so = stackexchange.Site(stackexchange.StackOverflow,api_key)\n",
    "so.be_inclusive()\n",
    "so.impose_throttling = True\n",
    "so.throttle_stop = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at a specific question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q_id = 30339155\n",
    "question = so.question(q_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "['a1', 'array', 'a2', 'array', 'a3', 'array', 'two', 'array', 'a1', 'a2', 'want', 'merg', 'togeth', 'result', 'a3', 'see', 'numpi', 'join', 'structur', 'array', 'also', 'concaten', 'two', 'array', 'vertic', 'answer', 'question', 'use', 'numpi', 'np', 'concaten', 'way', 'work', 'a3', 'np', 'concaten', 'a1', 'a2', 'axi', 'np', 'c_', 'a1', 'a2', 'also', 'np', 'r_', 'row', 'wise', 'merg']\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "p_stemmer = PorterStemmer()\n",
    "tokenizer = RegexpTokenizer('\\w+')\n",
    "\n",
    "tokens = [] #in the future make this a self attribute of a class\n",
    "score = 0\n",
    "view_count = question.view_count\n",
    "url = question.link\n",
    "\n",
    "def fetch_and_clean(text):\n",
    "    raw = BeautifulSoup(text, \"lxml\").get_text()\n",
    "    raw = raw.lower()\n",
    "    tokens = tokenizer.tokenize(raw)\n",
    "\n",
    "    tokens = [word for word in tokens if not word.isdigit()]\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    tokens = [p_stemmer.stem(i) for i in tokens]\n",
    "    return tokens\n",
    "\n",
    "tokens += fetch_and_clean(question.body)\n",
    "score += question.score\n",
    "\n",
    "if 'comments' in question.json.keys():\n",
    "    for comments in question.json['comments']:\n",
    "        tokens += fetch_and_clean(comments['body'])\n",
    "        score += comments['score']\n",
    "\n",
    "if 'answers' in question.json.keys():\n",
    "#if question.json['answer_count'] > 0:\n",
    "    for answers in question.json['answers']:\n",
    "        tokens += fetch_and_clean(answers['body'])\n",
    "        score += answers['score']\n",
    "        if 'comments' in answers.keys():\n",
    "            for comments in answers['comments']:\n",
    "                tokens += fetch_and_clean(comments['body'])\n",
    "                score += comments['score']\n",
    "                \n",
    "print(score)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "tokenizer = RegexpTokenizer('\\w+')\n",
    "\n",
    "class acquire_SO_question_info:\n",
    "    def __init__(self,q_id):\n",
    "        self.question = so.question(q_id)\n",
    "        self.tokens = []\n",
    "        self.raw = []\n",
    "        self.score = 0\n",
    "        self.view_count = question.view_count\n",
    "        self.url = question.link\n",
    "        \n",
    "    def fetch_and_clean(self,text):\n",
    "        raw = BeautifulSoup(text, \"lxml\").get_text()\n",
    "        raw = raw.lower()\n",
    "        self.raw += [raw]\n",
    "        tokens = tokenizer.tokenize(raw)\n",
    "\n",
    "        tokens = [word for word in tokens if not word.isdigit()]\n",
    "        tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "        tokens = [p_stemmer.stem(i) for i in tokens]\n",
    "        return tokens       \n",
    "    \n",
    "    def get_Info(self,text_type):\n",
    "        text_match = text_type\n",
    "        \n",
    "        if text_type.lower() == 'question':\n",
    "            text_source = self.question\n",
    "            text_match = None\n",
    "        else:\n",
    "            text_source = self.question.json\n",
    "            \n",
    "            \n",
    "        if text_match == None:\n",
    "            self.tokens += self.fetch_and_clean(text_source.body)\n",
    "            self.score += text_source.score\n",
    "        elif text_match in text_source.keys():\n",
    "            for text in text_source[text_match]:\n",
    "                self.tokens += self.fetch_and_clean(text['body'])\n",
    "                self.score += text['score']\n",
    "                if 'comments' in text.keys():\n",
    "                    for comments in text['comments']:\n",
    "                        self.tokens += self.fetch_and_clean(comments['body'])\n",
    "                        self.score += comments['score']\n",
    "        return self.tokens\n",
    "    \n",
    "    def get_sources(self):\n",
    "        self.get_Info('question')\n",
    "        self.get_Info('comments')\n",
    "        self.get_Info('answers')\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SO = acquire_SO_question_info(30339155)\n",
    "SO.get_sources()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:insight]",
   "language": "python",
   "name": "conda-env-insight-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
