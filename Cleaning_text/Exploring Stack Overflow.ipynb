{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries and get stockoverflow library set up to make api requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import stackexchange\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "api_key = '5*wCDZgONnIJ*aiaYeKjQQ(('\n",
    "\n",
    "so = stackexchange.Site(stackexchange.StackOverflow,api_key)\n",
    "so.be_inclusive()\n",
    "so.impose_throttling = True\n",
    "so.throttle_stop = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at a specific question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "p_stemmer = PorterStemmer()\n",
    "tokenizer = RegexpTokenizer('\\w+')\n",
    "\n",
    "class acquire_SO_question_info:\n",
    "    def __init__(self,q_id, search=True):\n",
    "        if search == True:\n",
    "            self.question = so.question(q_id)\n",
    "            self.id = q_id\n",
    "        else:\n",
    "            self.question = q_id\n",
    "            self.id = q_id.id\n",
    "            \n",
    "        self.tokens = []\n",
    "        self.raw = []\n",
    "        self.score = 0\n",
    "        self.view_count = question.view_count\n",
    "        self.url = question.link\n",
    "        \n",
    "    def fetch_and_clean(self,text):\n",
    "        raw = BeautifulSoup(text, \"lxml\").get_text()\n",
    "        raw = raw.lower()\n",
    "        self.raw += [raw]\n",
    "        tokens = tokenizer.tokenize(raw)\n",
    "\n",
    "        tokens = [word for word in tokens if not word.isdigit()]\n",
    "        tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "        tokens = [p_stemmer.stem(i) for i in tokens]\n",
    "        return tokens       \n",
    "    \n",
    "    def get_Info(self,text_type):\n",
    "        text_match = text_type\n",
    "        \n",
    "        if text_type.lower() == 'question':\n",
    "            text_source = self.question\n",
    "            text_match = None\n",
    "        else:\n",
    "            text_source = self.question.json\n",
    "            \n",
    "            \n",
    "        if text_match == None:\n",
    "            self.tokens += self.fetch_and_clean(text_source.body)\n",
    "            self.score += text_source.score\n",
    "        elif text_match in text_source.keys():\n",
    "            for text in text_source[text_match]:\n",
    "                self.tokens += self.fetch_and_clean(text['body'])\n",
    "                self.score += text['score']\n",
    "                if 'comments' in text.keys():\n",
    "                    for comments in text['comments']:\n",
    "                        self.tokens += self.fetch_and_clean(comments['body'])\n",
    "                        self.score += comments['score']\n",
    "        return self.tokens\n",
    "    \n",
    "    def get_sources(self):\n",
    "        self.get_Info('question')\n",
    "        self.get_Info('comments')\n",
    "        self.get_Info('answers')\n",
    "        pass\n",
    "    \n",
    "    def get_df_data(self):\n",
    "        return [self.id, self.score,self.view_count,self.url]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rawtext_dict = {}\n",
    "text_dict = {}\n",
    "data = []\n",
    "\n",
    "Data_file = open('Python_StackOverflow_Data.csv', 'w')\n",
    "Txt_file = open('Python_StackOverflow_Txt.csv', 'w')\n",
    "#Raw_file = open('Python_StackOverflow_RawTxt.csv', 'w')\n",
    "\n",
    "for i,question in enumerate(so.questions(tagged=['python'], pagesize=10)):\n",
    "    StackObj = acquire_SO_question_info(question,search=False)\n",
    "    StackObj.get_sources()\n",
    "\n",
    "    #text_dict[StackObj.id] = StackObj.tokens #text to dictionary\n",
    "    #data.append(StackObj.get_df_data())\n",
    "    #rawtext_dict[StackObj.id] = StackObj.raw\n",
    "\n",
    "    Data_file.write(\"%d,%d,%d,%s\\n\" % (StackObj.id, StackObj.score, StackObj.view_count, StackObj.url))\n",
    "    Txt_file.write(\"%d,%s\\n\" % (StackObj.id, StackObj.tokens))\n",
    "    #Raw_file.write(\"%d,%s\\n\" % (StackObj.id, StackObj.raw))\n",
    "\n",
    "    if i % 1000==0: print(i)\n",
    "    #if i == 3: break\n",
    "\n",
    "Data_file.close()\n",
    "Data_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "some of this might be out of data so check out the python file for downloading data from stackoverflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:insight]",
   "language": "python",
   "name": "conda-env-insight-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
